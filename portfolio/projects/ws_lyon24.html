<!DOCTYPE html>
<html lang="en">
<html data-theme="cmyk">

</html>

<head>
    <meta charset="UTF-8">
    <link href="output.css" rel="stylesheet">
    <script src="js/theme.js" defer></script>
</head>


<body class="bg-white-100 text-black-900">
    <!-- background -->
    <div class="relative min-h-screen overflow-y-auto">
        <div class="wrapper">
            <div class="box">
                <div></div>
                <div></div>
                <div></div>
                <div></div>
                <div></div>
                <div></div>
                <div></div>
                <div></div>
                <div></div>
                <div></div>
            </div>
        </div>

    <!-- Project Window -->
    <div class="flex justify-center">
        <div class="w-1/6 aspect-square overflow-hidden rounded-2xl">
            <img src="img/worldskills/lyon24/ws_lyon24.jpg" class="w-full h-full object-cover hover:scale-110 duration-300" />
        </div>
    </div>
    <p class="mt-4 text-center font-bold">
        WorldSkills Lyon 2024 was the final chapter of my WorldSkills journey. Over eight months, I worked on building and programming an autonomous robot from the ground up. The robot was designed to navigate on its own and interact with objects in a dynamic environment. I used a ROS2 stack for the entire project. While my coach gave me some guidance, most of what I learned came from exploring solutions online, testing ideas, and pushing myself to improve.
    </p>
    
    <br>
    <div class="flex justify-center">
        <img src="img/worldskills/lyon24/medals.jpg"
             class="w-2/3 rounded-2xl object-cover hover:scale-110 duration-300 overflow-hidden" />
    </div>
    
    <p class="italic text-center">All my medals from my WorldSkills journey.</p>
    <p class="italic text-center">Left: Regional, Right: National, Center: Worlds</p>
    
    <div class="divider"></div>

    <p class="mt-4 text-center font-bold">
        Robot Overview
    </p>
    <p class="mt-4 text-center">
        The robot is based on a differential drive system with four motors with encoders and includes a lidar for mapping, a depth camera for detecting objects, and a three-jointed robotic arm with a rotating base for grabbing and moving objects.
    </p>
    <br>
    <div class="w-full object-cover aspect-video bg-black ">
        <iframe class="w-full h-full" src="https://www.youtube.com/embed/AhZSpFj_UJo" frameborder="0"
            allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
            allowfullscreen>
        </iframe>
    </div>
    <p class="italic text-center">Overview of the robot's design.</p>
    <br>
    <div class="flex gap-5 justify-center">
        <img src="img/worldskills/lyon24/pict_pixx_1.jpg"
            class="w-1/3 h-1/3 rounded-2xl object-cover hover:scale-110 duration-300 overflow-hidden" />
        <img src="img/worldskills/lyon24/pict_pixx_3.jpg"
            class="w-1/3 h-1/3 rounded-2xl object-cover hover:scale-110 duration-300 overflow-hidden" />
    </div>
    <br>
    <div class="flex gap-5 justify-center">
        <img src="img/worldskills/lyon24/pict_pixx_2.jpg"
                class="w-2/3 h-2/3 rounded-2xl object-cover hover:scale-110 duration-300 overflow-hidden" />
            </div>
    <p class="italic text-center">Some pictures of the robot.</p>

    <div class="divider"></div>
    
    <p class="mt-4 text-center font-bold">
        Navigation
    </p>
    <p class="mt-4 text-center">
        To handle navigation, I used SLAM (Simultaneous Localization and Mapping) to map the environment and then AMCL and Nav2 for planning paths and moving autonomously. For positioning, I combined data from the motor encoders (enhanced with a PID) and lidar using the RF2O odometry algorithm. This setup allowed the robot to move smoothly and accurately, even in challenging environments.
    </p>

    <div class="flex gap-5 justify-center">
        <video class="w-2/3 rounded-2xl object-cover  hover:scale-110 duration-300 " controls autoplay loop>
            <source
            src="img/worldskills/lyon24/newpid.mp4"
            type="video/mp4"
            />
        </video>
    </div>
    <p class="italic text-center">Tests and feedbacks of the encoders using the PID</p>
    <br>
    <div class="flex gap-5 justify-center">
        <img src="img/worldskills/lyon24/navproto.jpg"
        class="w-1/3 h-1/3 rounded-2xl object-cover hover:scale-110 duration-300 overflow-hidden" />
    </div>
    <p class="italic text-center">Picture with a prototype using nav2 and AMCL</p>
    <br>
    <div class="w-full object-cover aspect-video bg-black ">
        <iframe class="w-full h-full" src="https://www.youtube.com/embed/1ArNoJ4Ynxk" frameborder="0"
            allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
            allowfullscreen>
        </iframe>
    </div>
    <p class="italic text-center">Demo of a prototype using AMCL and NAV2 on a map created with SLAM. It also uses a behavior tree and image recognizion</p>
    <div class="divider"></div>
    
    <p class="mt-4 text-center font-bold">
        Behavior Tree
    </p>
    <p class="mt-4 text-center">
        To handle the robot’s behavior during the competition, I built a custom behavior tree (BT) system. Instead of using the default ROS-bt, I manually connected BehaviorTree.CPP v3 with ROS2 through a singleton pattern. This gave me more flexibility to design and adapt the robot’s behavior. I developed multiple BT nodes for specific tasks, which made it easy to adjust the robot’s actions for unexpected challenges during the competition.
    </p>
    <br>
    <div class="flex gap-5 justify-center items-center overflow-hidden">
        <a 
          href="img/worldskills/lyon24/behaviortree_exemple.png" 
          target="_blank" 
          rel="noopener noreferrer" 
          class="w-5/6"
        >
          <img
            src="img/worldskills/lyon24/behaviortree_exemple.png"
            class="rounded-2xl object-cover hover:scale-110 duration-300 cursor-pointer"
          />
        </a>
    </div>
    <p class="italic text-center">Example of a simple behavior tree</p>
    <br>
    <div class="flex gap-5 justify-center items-center overflow-hidden">
        <a 
          href="img/worldskills/lyon24/behaviortree_class.png" 
          target="_blank" 
          rel="noopener noreferrer" 
          class="w-5/6"
        >
          <img
            src="img/worldskills/lyon24/behaviortree_class.png"
            class="rounded-2xl object-cover hover:scale-110 duration-300 cursor-pointer"
          />
        </a>
    </div>
    <p class="italic text-center">Some classes from the behavior tree stack</p>

    <div class="divider"></div>
    
    <p class="mt-4 text-center font-bold">
        Image Recognition
    </p>
    <p class="mt-4 text-center">
        For object detection, I used YOLO and learned how it works in detail. With a custom data augmentation script I wrote, I was able to train the model to recognize objects quickly, even with just a few sample images. The process was fast and efficient, taking less than five minutes to prepare the model for new objects. This made the robot very adaptable to the competition's requirements.
    </p>
    <br>

    <div class="flex gap-5 justify-center">
        <img src="img/worldskills/lyon24/augmented_data.jpg"
            class="w-5/6 h-5/6 rounded-2xl object-cover hover:scale-110 duration-300 overflow-hidden" />
    </div>
    <p class="italic text-center">Data augmentation example.</p>

    <div class="flex gap-5 justify-center">
        <img src="img/worldskills/lyon24/fruits_detection.png"
            class="w-1/3 h-1/3 rounded-2xl object-cover hover:scale-110 duration-300 overflow-hidden" />
        <img src="img/worldskills/lyon24/grapes_detection.png"
            class="w-1/3 h-1/3 rounded-2xl object-cover hover:scale-110 duration-300 overflow-hidden" />
    </div>
    <p class="italic text-center">Some examples of recognizion.</p>

    <div class="divider"></div>
    
    <p class="mt-4 text-center font-bold">
        Inverse Kinematics
    </p>
    <p class="mt-4 text-center">
        I used the depth camera to locate objects in 3D space and translated their position into the robot's coordinate system using ROS2. Then, I applied inverse kinematics to control the robotic arm and accurately reach and manipulate the objects.
    </p>
    <br>
    <div class="flex gap-5 justify-center">
        <img src="img/worldskills/lyon24/disp1.png"
            class="w-1/3 h-1/3 rounded-2xl object-cover hover:scale-110 duration-300 overflow-hidden" />
        <img src="img/worldskills/lyon24/disp2.png"
            class="w-1/3 h-1/3 rounded-2xl object-cover hover:scale-110 duration-300 overflow-hidden" />
    </div>
    <p class="italic text-center">The green dot represents the relative 3d positions of the object from the camera.</p>
    <br>
    <div class="flex gap-5 justify-center">
        <video class="w-2/3 rounded-2xl object-cover  hover:scale-110 duration-300 " controls autoplay loop>
            <source
            src="img/worldskills/lyon24/inversekinematics.mp4"
            type="video/mp4"
            />
        </video>
    </div>
    <p class="italic text-center">The arm follow the 3D position of the objects using inverse kinematics.</p>
    <div class="divider"></div>
    
    <br>
    <div class="flex gap-5 justify-center">
        <video class="w-2/3 rounded-2xl object-cover  hover:scale-110 duration-300 " controls autoplay loop>
            <source
            src="img/worldskills/lyon24/inversekinematics2.mp4"
            type="video/mp4"
            />
        </video>
    </div>
    <p class="italic text-center">The green dot simulates an object position. It is sent on a topic, then the inverse kinmatics node calculates the joints position and publishes it on another topic that can be understood by both the real robot and the Unity simulation.</p>
    <div class="divider"></div>
    

    <p class="mt-4 text-center font-bold">
        Competition Overview
    </p>

    We had diffent tasks during the 4 days of the competition. The tasks were:
    <ul>
        <li>- Prototyping</li>
        <li>- Object Detection</li>
        <li>- Object manipulation</li>
        <li>- Navigate in a 4x4m court</li>
    </ul>

    <br>
    The object detection was pretty hard since we had to detect 12 different eggs which had only few difference such as size, light color offset (like clear blue and white).
    <div class="flex gap-5 justify-center items-center overflow-hidden">
        <a 
          href="img/worldskills/lyon24/moduleE.png" 
          target="_blank" 
          rel="noopener noreferrer" 
          class="w-5/6"
        >
          <img
            src="img/worldskills/lyon24/moduleE.png"
            class="rounded-2xl object-cover hover:scale-110 duration-300 cursor-pointer"
          />
        </a>
    </div>

    <br>
    Then, for 2 days we had different task in the court such as harvesting apples and planting seeds. But we had to follow the client orders which were random.
    <div class="flex gap-5 justify-center items-center overflow-hidden">
        <a 
          href="img/worldskills/lyon24/ModuleH.png" 
          target="_blank" 
          rel="noopener noreferrer" 
          class="w-5/6"
        >
          <img
            src="img/worldskills/lyon24/ModuleH.png"
            class="rounded-2xl object-cover hover:scale-110 duration-300 cursor-pointer"
          />
        </a>
</body>

</html>